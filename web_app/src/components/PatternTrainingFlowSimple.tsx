import React, { useState, useEffect, useCallback, useRef } from 'react';
import { useLocalStorage, STORAGE_KEYS } from '@/hooks/useLocalStorage';
import { getCountdownDuration, type SpeakingStage } from '@/utils/speakingStageUtils';

interface PatternTrainingFlowSimpleProps {
  koreanText: string;
  expectedEnglish: string;
  onResult: (userAnswer: string, isCorrect: boolean, confidence: number, responseTime: number) => void;
  onError?: (error: string) => void;
  stage: number;
  disabled?: boolean;
  autoStart?: boolean;
  className?: string;
  mistakeId?: string;
  showCorrectAnswer?: boolean;
}

type FlowPhase = 'idle' | 'tts' | 'countdown' | 'recognition' | 'completed';

export const PatternTrainingFlowSimple: React.FC<PatternTrainingFlowSimpleProps> = ({
  koreanText,
  expectedEnglish,
  onResult,
  onError,
  stage,
  disabled = false,
  autoStart = false,
  className = '',
  mistakeId,
  showCorrectAnswer = true
}) => {
  // State management
  const [currentPhase, setCurrentPhase] = useState<FlowPhase>('idle');
  const [countdownTimer, setCountdownTimer] = useState<number>(0);
  const [recognitionTimer, setRecognitionTimer] = useState<number>(0);
  const [speechResult, setSpeechResult] = useState<string>('');
  const [showAnswer, setShowAnswer] = useState<boolean>(false);
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [ttsInitialized, setTtsInitialized] = useState<boolean>(false);
  
  // Timing
  const [recognitionStartTime, setRecognitionStartTime] = useState<number>(0);
  
  // Voice settings
  const { value: voiceSettings } = useLocalStorage(STORAGE_KEYS.VOICE_SETTINGS);
  
  // Refs for cleanup
  const recognitionRef = useRef<any>(null);
  const countdownIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const timerIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // Get stage-based timing using utility function
  const getCountdownTime = () => {
    // ALL modeë‚˜ ê¸°íƒ€ ë‹¨ê³„ëŠ” 2ì´ˆ, ì •ê·œ ë‹¨ê³„ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
    if (stage >= 1 && stage <= 3) {
      return getCountdownDuration(stage as SpeakingStage);
    }
    return 2; // ALL mode: 2ì´ˆ
  };

  /**
   * ğŸ”§ í”ŒëŸ¬ê·¸ì¸ì„ í†µí•œ TTS ì´ˆê¸°í™”
   */
  const initializeTTS = useCallback(async () => {
    if (ttsInitialized) {
      return Promise.resolve();
    }

    try {
      console.log('ğŸ”§ í”ŒëŸ¬ê·¸ì¸ TTS ì´ˆê¸°í™” ì‹œì‘...');

      // ServiceContainerë¥¼ í†µí•´ speechService ì‚¬ìš©
      const ServiceContainer = (await import('@/container/ServiceContainer')).default;
      const container = ServiceContainer.getInstanceSync();
      container.getSpeechProcessingService(); // ì´ˆê¸°í™”ë§Œ ìˆ˜í–‰

      // í”ŒëŸ¬ê·¸ì¸ì„ í†µí•œ ì´ˆê¸°í™” (ì‹¤ì œ ìŒì„± ì—†ì´ ì¤€ë¹„ë§Œ)
      console.log('ğŸ”§ í”ŒëŸ¬ê·¸ì¸ TTS ì´ˆê¸°í™” ì™„ë£Œ');
      setTtsInitialized(true);
      return Promise.resolve();
    } catch (error) {
      console.warn('ğŸ”§ í”ŒëŸ¬ê·¸ì¸ TTS ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
      setTtsInitialized(true);
      return Promise.resolve();
    }
  }, [ttsInitialized]);

  /**
   * ğŸ”§ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œì„ í†µí•œ Text-to-Speech í•¨ìˆ˜
   */
  const speakText = useCallback(async (text: string, lang: 'ko' | 'en' = 'ko'): Promise<void> => {
    try {
      // Initialize TTS if not already done
      if (!ttsInitialized) {
        await initializeTTS();
      }

      // Check if voice is enabled for this language
      if (lang === 'ko' && !voiceSettings.koreanEnabled) {
        return;
      }
      if (lang === 'en' && !voiceSettings.englishEnabled) {
        return;
      }

      // ServiceContainerë¥¼ í†µí•´ speechService ì‚¬ìš©
      const ServiceContainer = (await import('@/container/ServiceContainer')).default;
      const container = ServiceContainer.getInstanceSync();
      const speechService = container.getSpeechProcessingService();

      // ê¸°ì¡´ TTS ì¤‘ì§€
      speechService.stopAllSpeech();

      // í”ŒëŸ¬ê·¸ì¸ì„ í†µí•´ TTS ì‹¤í–‰
      await speechService.speakAnswer(text, {
        language: lang === 'ko' ? 'ko-KR' : 'en-US',
        rate: voiceSettings.speed,
        volume: 1.0,
        pitch: 1.0
      });

      console.log(`ğŸ”§ ${lang.toUpperCase()} TTS ì™„ë£Œ (í”ŒëŸ¬ê·¸ì¸)`);

    } catch (error) {
      console.error(`ğŸ”§ [PatternTrainingFlowSimple] Speech service error:`, error);

      // ğŸ”§ í”ŒëŸ¬ê·¸ì¸ fallback: AdvancedSpeechPlugin ì‹œë„
      try {
        const ServiceContainer = (await import('@/container/ServiceContainer')).default;
        const container = ServiceContainer.getInstanceSync();
        const advancedPlugin = container.getAdvancedSpeechPlugin();

        if (advancedPlugin) {
          // ê¸°ì¡´ TTS ì¤‘ì§€
          advancedPlugin.stopAll();

          await advancedPlugin.speakText(text, {
            language: lang === 'ko' ? 'ko-KR' : 'en-US',
            rate: voiceSettings.speed,
            volume: 1.0,
            pitch: 1.0
          });

          console.log(`ğŸ”§ ${lang.toUpperCase()} TTS ì™„ë£Œ (ê³ ê¸‰ í”ŒëŸ¬ê·¸ì¸)`);
        } else {
          console.warn(`ğŸ”§ [PatternTrainingFlowSimple] No speech plugins available`);
        }
      } catch (pluginError) {
        console.error(`ğŸ”§ [PatternTrainingFlowSimple] All speech plugins failed:`, pluginError);
      }
    }
  }, [voiceSettings, ttsInitialized, initializeTTS]);

  /**
   * Force stop all timers and activities
   */
  const forceStopAllTimers = useCallback(() => {
    try {
      // Clear countdown interval
      if (countdownIntervalRef.current) {
        clearInterval(countdownIntervalRef.current);
        countdownIntervalRef.current = null;
      }
      
      // Clear recording timeout
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
        recordingTimeoutRef.current = null;
      }

      // Clear timer interval
      if (timerIntervalRef.current) {
        clearInterval(timerIntervalRef.current);
        timerIntervalRef.current = null;
      }
      
      // Stop speech recognition safely
      if (recognitionRef.current && isRecording) {
        try {
          recognitionRef.current.stop();
        } catch (error) {
          console.warn('Error stopping speech recognition:', error);
        }
      }
      
      // ğŸ”§ í”ŒëŸ¬ê·¸ì¸ì„ í†µí•œ TTS ì¤‘ì§€ (ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬)
      try {
        import('@/container/ServiceContainer').then((module) => {
          const container = module.default.getInstanceSync();
          const speechService = container.getSpeechProcessingService();
          speechService.stopAllSpeech();
        }).catch((error) => {
          console.warn('ğŸ”§ Error stopping TTS (plugin):', error);
        });
      } catch (error) {
        console.warn('ğŸ”§ Error importing ServiceContainer:', error);
      }
      
      setIsRecording(false);
    } catch (error) {
      console.error('Error in forceStopAllTimers:', error);
      setIsRecording(false);
    }
  }, [isRecording]);

  /**
   * Start speech recognition
   */
  const startSpeechRecognition = useCallback(() => {
    if (currentPhase === 'recognition' || isRecording) {
      console.log('ìŒì„±ì¸ì‹ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ - ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€');
      return;
    }
    
    setCurrentPhase('recognition');
    console.log('ìŒì„±ì¸ì‹ ì‹œì‘ - 6ì´ˆ ì œí•œì‹œê°„');
    
    forceStopAllTimers();
    
    if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
      const errorMsg = 'ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.';
      setSpeechResult(errorMsg);
      onError?.(errorMsg);
      return;
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US';
    recognition.maxAlternatives = 3;

    recognitionRef.current = recognition;
    setIsRecording(true);
    setSpeechResult('ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...');

    let hasReceivedResult = false;
    let recognitionStopped = false;

    recognition.onstart = () => {
      if (recognitionStopped) return;
      console.log('ìŒì„±ì¸ì‹ ì‹¤ì œ ì‹œì‘');
      setRecognitionTimer(0);
      setRecognitionStartTime(Date.now());
      
      // Start timer
      const interval = setInterval(() => {
        setRecognitionTimer(prev => prev + 0.1);
      }, 100);
      timerIntervalRef.current = interval;
      
      // 6ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
      recordingTimeoutRef.current = setTimeout(() => {
        if (!hasReceivedResult && !recognitionStopped) {
          console.log('6ì´ˆ íƒ€ì„ì•„ì›ƒ - ê°•ì œ ì¤‘ì§€');
          recognitionStopped = true;
          recognition.stop();
          handleRecognitionTimeout();
        }
      }, 6000);
    };

    recognition.onresult = (event: any) => {
      if (hasReceivedResult || recognitionStopped) {
        console.log('ì¤‘ë³µ ë‹µë³€ ì‹œë„ ì°¨ë‹¨');
        return;
      }
      
      hasReceivedResult = true;
      recognitionStopped = true;
      
      const result = event.results[0][0].transcript.trim();
      const confidence = event.results[0][0].confidence || 0.9;
      
      console.log(`ìŒì„±ì¸ì‹ ê²°ê³¼: "${result}" (ì‹ ë¢°ë„: ${confidence})`);
      
      // ì¦‰ì‹œ ì¸ì‹ ì¤‘ì§€
      recognition.stop();
      stopSpeechRecognition();
      
      // ê²°ê³¼ í‰ê°€ ë° ì „ë‹¬
      evaluateAndSubmitAnswer(result, confidence);
    };

    recognition.onerror = (event: any) => {
      console.error('ìŒì„±ì¸ì‹ ì˜¤ë¥˜:', event.error);
      stopSpeechRecognition();
      
      switch (event.error) {
        case 'no-speech':
          handleRecognitionTimeout();
          break;
        case 'audio-capture':
          const audioError = 'ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
          setSpeechResult(audioError);
          onError?.(audioError);
          break;
        case 'not-allowed':
          const permissionError = 'ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
          setSpeechResult(permissionError);
          onError?.(permissionError);
          break;
        case 'network':
          const networkError = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
          setSpeechResult(networkError);
          onError?.(networkError);
          break;
        case 'aborted':
          console.log('ìŒì„± ì¸ì‹ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.');
          setCurrentPhase('idle');
          break;
        default:
          const errorMsg = `ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`;
          setSpeechResult(errorMsg);
          onError?.(errorMsg);
      }
    };

    recognition.onend = () => {
      console.log('ìŒì„±ì¸ì‹ ì¢…ë£Œ');
      if (!hasReceivedResult && !recognitionStopped) {
        recognitionStopped = true;
        handleRecognitionTimeout();
      }
    };

    try {
      recognition.start();
    } catch (error) {
      console.error('ìŒì„±ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:', error);
      stopSpeechRecognition();
      const errorMsg = 'ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      setSpeechResult(errorMsg);
      onError?.(errorMsg);
    }
  }, [isRecording, forceStopAllTimers, onError]);

  /**
   * Stop speech recognition safely
   */
  const stopSpeechRecognition = useCallback(() => {
    if (recognitionRef.current && isRecording) {
      recognitionRef.current.stop();
    }
    setIsRecording(false);
    
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = null;
    }

    if (timerIntervalRef.current) {
      clearInterval(timerIntervalRef.current);
      timerIntervalRef.current = null;
    }
  }, [isRecording]);

  /**
   * Handle recognition timeout
   */
  const handleRecognitionTimeout = useCallback(() => {
    console.log('ìŒì„±ì¸ì‹ íƒ€ì„ì•„ì›ƒ');
    setCurrentPhase('completed');
    setSpeechResult('ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
    
    // íƒ€ì„ì•„ì›ƒì„ ì˜¤ë‹µìœ¼ë¡œ ì²˜ë¦¬
    onResult('', false, 0, 0);
  }, [onResult]);

  /**
   * Evaluate user answer and submit result
   */
  const evaluateAndSubmitAnswer = useCallback((userAnswer: string, confidence: number) => {
    const isCorrect = userAnswer.toLowerCase().trim() === expectedEnglish.toLowerCase().trim();
    const responseTime = recognitionStartTime ? Date.now() - recognitionStartTime : 0;
    
    console.log(`ë‹µë³€ í‰ê°€: "${userAnswer}" vs "${expectedEnglish}" = ${isCorrect ? 'ì •ë‹µ' : 'ì˜¤ë‹µ'}`);
    
    setCurrentPhase('completed');
    setSpeechResult(`ì¸ì‹ëœ ë‹µë³€: "${userAnswer}"`);
    
    // Show correct answer if enabled and answer was wrong
    if (showCorrectAnswer && !isCorrect) {
      setShowAnswer(true);
      // Always speak the correct answer in English when wrong (new enhancement)
      console.log(`í‹€ë¦° ë‹µë³€ - ì •ë‹µ TTS ì¬ìƒ: "${expectedEnglish}"`);
      setTimeout(() => {
        speakText(expectedEnglish, 'en').catch(error => {
          console.warn('ì˜ì–´ TTS ì‹¤íŒ¨:', error);
        });
      }, 500); // Shorter delay for better user experience
    }
    
    // ê²°ê³¼ ì „ë‹¬
    onResult(userAnswer, isCorrect, confidence, responseTime);
  }, [expectedEnglish, onResult, recognitionStartTime, showCorrectAnswer, voiceSettings.englishEnabled, speakText]);

  /**
   * Play beep sound before speech recognition (matching original HTML)
   */
  const playMicrophoneStartSound = useCallback(() => {
    if ('AudioContext' in window || 'webkitAudioContext' in window) {
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      const audioCtx = new AudioContext();
      
      const oscillator = audioCtx.createOscillator();
      const gainNode = audioCtx.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(audioCtx.destination);
      
      oscillator.frequency.setValueAtTime(800, audioCtx.currentTime);
      gainNode.gain.setValueAtTime(0.3, audioCtx.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioCtx.currentTime + 0.2);
      
      oscillator.start(audioCtx.currentTime);
      oscillator.stop(audioCtx.currentTime + 0.2);
    }
  }, []);

  /**
   * Start countdown before speech recognition (matching original HTML flow)
   */
  const startCountdownBeforeSpeechRecognition = useCallback(() => {
    setCurrentPhase('countdown');
    const waitTime = getCountdownTime();
    
    console.log(`ì‚¬ê³ ì‹œê°„ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘ - ${waitTime}ì´ˆ ëŒ€ê¸°`);
    
    forceStopAllTimers();
    
    setCountdownTimer(waitTime);
    
    countdownIntervalRef.current = setInterval(() => {
      setCountdownTimer(prev => {
        const remaining = prev - 1;
        console.log(`ì‚¬ê³ ì‹œê°„ ë‚¨ìŒ: ${remaining}ì´ˆ`);
        
        if (remaining <= 0) {
          if (countdownIntervalRef.current) {
            clearInterval(countdownIntervalRef.current);
            countdownIntervalRef.current = null;
          }
          
          // Play beep sound before speech recognition (like original HTML)
          console.log('ğŸ”” ì‚¬ê³ ì‹œê°„ ì¢…ë£Œ - ë§ˆì´í¬ ì‹œì‘ìŒ ì¬ìƒ');
          playMicrophoneStartSound();
          
          // Start speech recognition immediately after beep
          setTimeout(() => {
            console.log('ğŸ¤ ìŒì„±ì¸ì‹ í•¨ìˆ˜ í˜¸ì¶œ ì‹œì‘');
            startSpeechRecognition();
          }, 100); // Small delay to ensure beep plays
        }
        return remaining;
      });
    }, 1000);
  }, [getCountdownTime, forceStopAllTimers, startSpeechRecognition, playMicrophoneStartSound]);

  /**
   * Main flow start function with proper TTS initialization
   */
  const startFlow = useCallback(async () => {
    if (disabled || !koreanText) return;
    
    console.log('Pattern Training Flow ì‹œì‘');
    
    // Reset all states
    setCurrentPhase('tts');
    setSpeechResult('');
    setCountdownTimer(0);
    setRecognitionTimer(0);
    setShowAnswer(false);
    
    try {
      // Initialize TTS first (handles browser autoplay policy)
      if (!ttsInitialized) {
        console.log('TTS ì´ˆê¸°í™” ì¤‘...');
        await initializeTTS();
      }
      
      // Step 1: Play Korean TTS
      console.log(`í•œêµ­ì–´ TTS ì‹œì‘: "${koreanText}"`);
      await speakText(koreanText, 'ko');
      
      // Step 2: Start countdown immediately after TTS (no additional delay)
      startCountdownBeforeSpeechRecognition();
      
    } catch (error) {
      console.error('Flow ì‹œì‘ ì˜¤ë¥˜:', error);
      setCurrentPhase('idle');
      const errorMsg = error instanceof Error ? error.message : 'Flow ì‹œì‘ ì‹¤íŒ¨';
      onError?.(errorMsg);
    }
  }, [disabled, koreanText, speakText, startCountdownBeforeSpeechRecognition, onError, ttsInitialized, initializeTTS]);

  // Auto-start effect (prevent duplicate execution)
  useEffect(() => {
    if (autoStart && koreanText && currentPhase === 'idle' && !disabled) {
      console.log('Auto-start triggered for:', koreanText);
      startFlow();
    }
  }, [koreanText]); // Only depend on koreanText to prevent re-execution

  // Cleanup effect on unmount
  useEffect(() => {
    return () => {
      try {
        forceStopAllTimers();
        setCurrentPhase('idle');
        setIsRecording(false);
        
        if (recognitionRef.current) {
          try {
            recognitionRef.current.abort();
          } catch (error) {
            console.warn('Error aborting recognition on unmount:', error);
          }
          recognitionRef.current = null;
        }
        
        try {
          // ğŸ”§ í”ŒëŸ¬ê·¸ì¸ì„ í†µí•œ TTS ì¤‘ì§€ (ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬)
          import('@/container/ServiceContainer').then((module) => {
            const container = module.default.getInstanceSync();
            const speechService = container.getSpeechProcessingService();
            speechService.stopAllSpeech();
          }).catch((error) => {
            console.warn('ğŸ”§ Error stopping TTS on unmount (plugin):', error);
          });
        } catch (error) {
          console.warn('ğŸ”§ Error importing ServiceContainer on unmount:', error);
        }
        
        console.log('PatternTrainingFlowSimple cleanup completed');
      } catch (error) {
        console.error('Error during cleanup:', error);
      }
    };
  }, [forceStopAllTimers]);

  return (
    <div className={`text-center ${className}`}>
      {/* Korean text display */}
      <div className="mb-8">
        <div className="text-3xl font-bold text-gray-800 mb-4 min-h-[60px] flex items-center justify-center">
          {koreanText || 'ë¬¸ì œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...'}
        </div>
        
        {/* Show correct answer when enabled */}
        {showAnswer && showCorrectAnswer && (
          <div className="text-2xl font-semibold text-green-600 mb-4 animate-pulse">
            ì •ë‹µ: {expectedEnglish}
          </div>
        )}
      </div>

      {/* Flow status display */}
      {currentPhase !== 'idle' && (
        <div className="bg-blue-50 border border-blue-200 rounded-lg p-6 mb-6">
          <div className="text-center">
            <div className="text-lg font-semibold text-blue-800 mb-4">
              {currentPhase === 'tts' && 'ğŸ”Š ë¬¸ì œë¥¼ ë“¤ë ¤ë“œë¦¬ê³  ìˆìŠµë‹ˆë‹¤...'}
              {currentPhase === 'countdown' && `â³ ${countdownTimer}ì´ˆ í›„ ìŒì„± ì¸ì‹ ì‹œì‘...`}
              {currentPhase === 'recognition' && `ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”... (${recognitionTimer.toFixed(1)}ì´ˆ / 6ì´ˆ)`}
              {currentPhase === 'completed' && 'âœ… ì™„ë£Œ!'}
            </div>
            
            {/* Progress bar for recognition */}
            {currentPhase === 'recognition' && (
              <>
                <div className="w-full bg-blue-200 rounded-full h-2 mb-4">
                  <div 
                    className="bg-blue-600 h-2 rounded-full transition-all duration-100"
                    style={{ width: `${Math.min((recognitionTimer / 6) * 100, 100)}%` }}
                  />
                </div>
                
                <div className="flex items-center justify-center space-x-3">
                  <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                  <span className="text-sm text-blue-700">ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...</span>
                </div>
              </>
            )}
            
            {/* TTS indicator */}
            {currentPhase === 'tts' && (
              <div className="flex items-center justify-center space-x-3">
                <div className="w-3 h-3 bg-green-500 rounded-full animate-pulse"></div>
                <span className="text-sm text-blue-700">í•œêµ­ì–´ ë¬¸ì œë¥¼ ì¬ìƒ ì¤‘...</span>
              </div>
            )}
            
            {/* Countdown indicator */}
            {currentPhase === 'countdown' && (
              <div className="flex items-center justify-center space-x-3">
                <div className="w-3 h-3 bg-yellow-500 rounded-full animate-pulse"></div>
                <span className="text-sm text-blue-700">ìƒê°í•  ì‹œê°„ì„ ë“œë¦¬ê³  ìˆìŠµë‹ˆë‹¤</span>
              </div>
            )}
          </div>
        </div>
      )}

      {/* Speech result display */}
      {speechResult && (
        <div className="mb-4 p-4 bg-gray-50 border border-gray-200 rounded-lg">
          <div className="text-sm text-gray-600 mb-1">ìŒì„± ì¸ì‹ ê²°ê³¼:</div>
          <div className="font-medium text-gray-800">"{speechResult}"</div>
        </div>
      )}

      {/* Control buttons */}
      <div className="space-y-4">
        {/* Manual start button */}
        {currentPhase === 'idle' && !autoStart && (
          <button
            onClick={async () => {
              // Initialize TTS on user interaction to comply with autoplay policy
              if (!ttsInitialized) {
                await initializeTTS();
              }
              startFlow();
            }}
            disabled={disabled || !koreanText}
            className="px-8 py-4 bg-blue-600 text-white font-bold rounded-lg hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors text-lg"
          >
            ğŸ¤ ì‹œì‘í•˜ê¸°
          </button>
        )}
        
        {/* Emergency stop button */}
        {(currentPhase === 'tts' || currentPhase === 'countdown' || currentPhase === 'recognition') && (
          <button
            onClick={() => {
              forceStopAllTimers();
              setCurrentPhase('idle');
              onError?.('ì‚¬ìš©ìê°€ í”Œë¡œìš°ë¥¼ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.');
            }}
            className="px-4 py-2 bg-red-600 text-white font-medium rounded-lg hover:bg-red-700 transition-colors text-sm"
          >
            â¹ï¸ ì¤‘ì§€
          </button>
        )}
      </div>

      {/* Debug info (remove in production) */}
      {process.env.NODE_ENV === 'development' && (
        <div className="mt-4 text-xs text-gray-400 space-y-1">
          <div>Phase: {currentPhase}</div>
          <div>Stage: {stage} | Countdown: {getCountdownTime()}s</div>
          <div>Recording: {isRecording ? 'Yes' : 'No'}</div>
          <div>TTS Initialized: {ttsInitialized ? 'Yes' : 'No'}</div>
          <div>Voice: KO={voiceSettings.koreanEnabled ? 'On' : 'Off'} | EN={voiceSettings.englishEnabled ? 'On' : 'Off'} | Speed={voiceSettings.speed}x</div>
          {mistakeId && <div>Review Mode: {mistakeId}</div>}
        </div>
      )}
    </div>
  );
};