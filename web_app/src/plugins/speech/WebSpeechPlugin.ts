/**
 * Web Speech API í”ŒëŸ¬ê·¸ì¸ êµ¬í˜„
 * @description ë¸Œë¼ìš°ì €ì˜ Web Speech APIë¥¼ ì‚¬ìš©í•˜ëŠ” í”ŒëŸ¬ê·¸ì¸
 */

import { BasePlugin } from '@/plugins/core/BasePlugin';
import { 
  ISpeechPlugin, 
  SpeechPluginConfig, 
  SpeechProcessingState,
  SpeechPluginEvent,
  SpeechEventHandler 
} from './ISpeechPlugin';
import { 
  SpeechResult, 
  SpeechRecognitionResult,
  SpeechResultCallback 
} from '@/types/services';
import { 
  NonEmptyString, 
  PositiveNumber, 
  Result, 
  Ok, 
  Err,
  assertNonEmptyString,
  assertPositiveNumber 
} from '@/types/core';

/**
 * Web Speech API í”ŒëŸ¬ê·¸ì¸
 */
export class WebSpeechPlugin extends BasePlugin implements ISpeechPlugin {
  private _processingState: SpeechProcessingState = 'idle';
  private speechSynthesis?: SpeechSynthesis;
  private speechRecognition?: SpeechRecognition;
  private audioContext?: AudioContext;
  
  // í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—…ë“¤
  private currentUtterance?: SpeechSynthesisUtterance;
  private currentRecognition?: SpeechRecognition;
  
  // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
  private speechEventHandlers = new Set<SpeechEventHandler>();
  
  constructor() {
    super({
      name: assertNonEmptyString('web-speech', 'plugin name'),
      version: assertNonEmptyString('1.0.0', 'plugin version'),
      description: 'Web Speech API plugin for TTS and Speech Recognition',
      author: 'DaSi Team',
      tags: ['speech', 'tts', 'recognition', 'web-api']
    });
  }

  get processingState(): SpeechProcessingState {
    return this._processingState;
  }

  private setProcessingState(state: SpeechProcessingState): void {
    if (this._processingState !== state) {
      this._processingState = state;
      this.emitSpeechEvent({
        type: 'stateChange',
        timestamp: Date.now(),
        data: { state }
      });
    }
  }

  protected async onInitialize(config: SpeechPluginConfig): Promise<Result<void>> {
    return this.safeAsync(async () => {
      // Web Speech API ì§€ì› í™•ì¸
      if (!window.speechSynthesis) {
        throw new Error('SpeechSynthesis not supported');
      }

      // SpeechRecognition ì§€ì› í™•ì¸ (ì„ íƒì )
      const SpeechRecognitionConstructor = 
        window.SpeechRecognition || 
        (window as any).webkitSpeechRecognition;
      
      if (!SpeechRecognitionConstructor) {
        console.warn('SpeechRecognition not supported - TTS only mode');
      }

      this.speechSynthesis = window.speechSynthesis;
      
      if (SpeechRecognitionConstructor) {
        this.speechRecognition = new SpeechRecognitionConstructor();
        this.setupRecognition();
      }

      // AudioContext for beep sounds
      if (window.AudioContext || (window as any).webkitAudioContext) {
        const AudioContextConstructor = window.AudioContext || 
                                       (window as any).webkitAudioContext;
        this.audioContext = new AudioContextConstructor();
      }

      console.log('WebSpeechPlugin initialized successfully');
    }, 'Failed to initialize WebSpeechPlugin');
  }

  protected async onDispose(): Promise<Result<void>> {
    return this.safeAsync(async () => {
      // ëª¨ë“  ì²˜ë¦¬ ì¤‘ì§€
      this.stopAll();
      
      // AudioContext ì •ë¦¬
      if (this.audioContext && this.audioContext.state !== 'closed') {
        await this.audioContext.close();
      }

      // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬
      this.speechEventHandlers.clear();
      
      this.speechSynthesis = undefined;
      this.speechRecognition = undefined;
      this.audioContext = undefined;
      
      console.log('WebSpeechPlugin disposed successfully');
    }, 'Failed to dispose WebSpeechPlugin');
  }

  protected validateConfig(config: SpeechPluginConfig): Result<void> {
    try {
      if (config.speechRate && (config.speechRate <= 0 || config.speechRate > 3)) {
        return Err(new Error('speechRate must be between 0 and 3'));
      }
      return Ok(undefined);
    } catch (error) {
      return Err(error as Error);
    }
  }

  private setupRecognition(): void {
    if (!this.speechRecognition) return;

    const config = this.getConfig() as SpeechPluginConfig;
    
    this.speechRecognition.continuous = config.enableContinuous ?? false;
    this.speechRecognition.interimResults = config.enableInterimResults ?? true;
    this.speechRecognition.lang = config.recognitionLanguage || 'ko-KR';
  }

  /**
   * TTS êµ¬í˜„
   */
  async speakText(
    text: NonEmptyString, 
    options: {
      language?: NonEmptyString;
      rate?: PositiveNumber;
      volume?: number;
      pitch?: number;
    } = {}
  ): Promise<Result<SpeechResult>> {
    if (!this.speechSynthesis) {
      return Err(new Error('Speech synthesis not available'));
    }

    if (this._processingState === 'speaking') {
      return Err(new Error('Already speaking'));
    }

    return new Promise((resolve) => {
      try {
        const utterance = new SpeechSynthesisUtterance(text);
        const config = this.getConfig() as SpeechPluginConfig;
        
        // ì„¤ì • ì ìš©
        utterance.lang = options.language || config.synthesisLanguage || 'ko-KR';
        utterance.rate = options.rate || config.speechRate || 1.0;
        utterance.volume = options.volume ?? 1.0;
        utterance.pitch = options.pitch ?? 1.0;

        const startTime = Date.now();
        
        utterance.onstart = () => {
          this.setProcessingState('speaking');
          this.emitSpeechEvent({
            type: 'start',
            timestamp: Date.now()
          });
        };

        utterance.onend = () => {
          this.setProcessingState('idle');
          const duration = Date.now() - startTime;
          
          this.emitSpeechEvent({
            type: 'end',
            timestamp: Date.now()
          });

          resolve(Ok({
            success: true,
            duration: duration as PositiveNumber
          }));
        };

        utterance.onerror = (event) => {
          this.setProcessingState('error');
          const error = `TTS error: ${event.error}`;
          
          this.emitSpeechEvent({
            type: 'error',
            timestamp: Date.now(),
            data: { error }
          });

          resolve(Err(new Error(error)));
        };

        this.currentUtterance = utterance;
        this.speechSynthesis!.speak(utterance);
        
      } catch (error) {
        this.setProcessingState('error');
        resolve(Err(error as Error));
      }
    });
  }

  /**
   * ìŒì„± ì¸ì‹ êµ¬í˜„
   */
  async recognizeSpeech(
    options: {
      language?: NonEmptyString;
      maxDuration?: PositiveNumber;
      continuous?: boolean;
      interimResults?: boolean;
    } = {}
  ): Promise<Result<SpeechRecognitionResult>> {
    if (!this.speechRecognition) {
      return Err(new Error('Speech recognition not available'));
    }

    if (this._processingState === 'listening') {
      return Err(new Error('Already listening'));
    }

    return new Promise((resolve) => {
      try {
        const recognition = this.speechRecognition!;
        const config = this.getConfig() as SpeechPluginConfig;
        
        // ì„¤ì • ì ìš©
        recognition.lang = options.language || config.recognitionLanguage || 'ko-KR';
        recognition.continuous = options.continuous ?? false;
        recognition.interimResults = options.interimResults ?? true;

        let finalTranscript = '';
        let maxConfidence = 0;
        let hasResult = false;
        
        const cleanup = () => {
          this.setProcessingState('idle');
          this.currentRecognition = undefined;
        };

        recognition.onstart = () => {
          this.setProcessingState('listening');
          this.emitSpeechEvent({
            type: 'start',
            timestamp: Date.now()
          });
        };

        recognition.onresult = (event) => {
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const result = event.results[i];
            
            if (result.isFinal) {
              finalTranscript += result[0].transcript;
              maxConfidence = Math.max(maxConfidence, result[0].confidence);
              hasResult = true;
            }

            this.emitSpeechEvent({
              type: 'result',
              timestamp: Date.now(),
              data: {
                transcript: result[0].transcript as NonEmptyString,
                confidence: result[0].confidence
              }
            });
          }
        };

        recognition.onend = () => {
          cleanup();
          
          this.emitSpeechEvent({
            type: 'end',
            timestamp: Date.now()
          });

          if (hasResult && finalTranscript.trim()) {
            resolve(Ok({
              success: true,
              transcript: finalTranscript.trim() as NonEmptyString,
              confidence: maxConfidence,
              isFinal: true
            }));
          } else {
            resolve(Ok({
              success: false,
              error: 'No speech detected'
            }));
          }
        };

        recognition.onerror = (event) => {
          cleanup();
          const error = `Speech recognition error: ${event.error}`;
          
          this.emitSpeechEvent({
            type: 'error',
            timestamp: Date.now(),
            data: { error }
          });

          resolve(Err(new Error(error)));
        };

        // íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
        if (options.maxDuration) {
          setTimeout(() => {
            if (this._processingState === 'listening') {
              recognition.stop();
            }
          }, options.maxDuration);
        }

        this.currentRecognition = recognition;
        recognition.start();
        
      } catch (error) {
        this.setProcessingState('error');
        resolve(Err(error as Error));
      }
    });
  }

  /**
   * ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘
   */
  startListening(
    onResult: SpeechResultCallback,
    options: {
      language?: NonEmptyString;
      continuous?: boolean;
      interimResults?: boolean;
    } = {}
  ): Result<void> {
    if (!this.speechRecognition) {
      return Err(new Error('Speech recognition not available'));
    }

    if (this._processingState === 'listening') {
      return Err(new Error('Already listening'));
    }

    try {
      const recognition = this.speechRecognition;
      const config = this.getConfig() as SpeechPluginConfig;
      
      recognition.lang = options.language || config.recognitionLanguage || 'ko-KR';
      recognition.continuous = options.continuous ?? true;
      recognition.interimResults = options.interimResults ?? true;

      recognition.onresult = (event) => {
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          onResult(
            result[0].transcript as NonEmptyString,
            result[0].confidence
          );
        }
      };

      recognition.onstart = () => {
        this.setProcessingState('listening');
      };

      recognition.onend = () => {
        this.setProcessingState('idle');
        // ìë™ ì¬ì‹œì‘ (continuous ëª¨ë“œì—ì„œ)
        if (options.continuous && config.autoRestart) {
          setTimeout(() => {
            if (this._processingState === 'idle') {
              recognition.start();
            }
          }, 100);
        }
      };

      recognition.onerror = (event) => {
        this.setProcessingState('error');
        console.error('Speech recognition error:', event.error);
      };

      this.currentRecognition = recognition;
      recognition.start();
      
      return Ok(undefined);
    } catch (error) {
      return Err(error as Error);
    }
  }

  /**
   * ìŒì„± ì¸ì‹ ì¤‘ì§€
   */
  stopListening(): Result<void> {
    if (!this.currentRecognition) {
      return Ok(undefined);
    }

    try {
      this.currentRecognition.stop();
      this.currentRecognition = undefined;
      this.setProcessingState('idle');
      return Ok(undefined);
    } catch (error) {
      return Err(error as Error);
    }
  }

  /**
   * ì‹ í˜¸ìŒ ì¬ìƒ
   */
  async playBeep(
    options: {
      frequency?: PositiveNumber;
      duration?: PositiveNumber;
      volume?: number;
    } = {}
  ): Promise<Result<void>> {
    if (!this.audioContext) {
      return Err(new Error('AudioContext not available'));
    }

    return this.safeAsync(async () => {
      const context = this.audioContext!;
      const frequency = options.frequency || (800 as PositiveNumber);
      const duration = options.duration || (200 as PositiveNumber);
      const volume = options.volume ?? 0.3;

      // AudioContextê°€ suspended ìƒíƒœë©´ resume
      if (context.state === 'suspended') {
        await context.resume();
      }

      const oscillator = context.createOscillator();
      const gainNode = context.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(context.destination);
      
      oscillator.frequency.value = frequency;
      oscillator.type = 'sine';
      
      gainNode.gain.setValueAtTime(0, context.currentTime);
      gainNode.gain.linearRampToValueAtTime(volume, context.currentTime + 0.01);
      gainNode.gain.exponentialRampToValueAtTime(0.01, context.currentTime + duration / 1000);
      
      oscillator.start(context.currentTime);
      oscillator.stop(context.currentTime + duration / 1000);
      
      return new Promise<void>((resolve) => {
        oscillator.onended = () => resolve();
      });
    }, 'Failed to play beep');
  }

  /**
   * ëª¨ë“  ì²˜ë¦¬ ì¤‘ì§€ - ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°•í™”
   */
  stopAll(): Result<void> {
    try {
      // TTS ì¤‘ì§€ - ë‹¤ì¤‘ ì·¨ì†Œ ì‹œë„ë¡œ ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ë³´
      if (this.speechSynthesis) {
        this.speechSynthesis.cancel();
        this.currentUtterance = undefined;
        
        // ë¸Œë¼ìš°ì €ë³„ ì•ˆì „ì„ ìœ„í•´ ì—¬ëŸ¬ ë²ˆ ì‹œë„
        setTimeout(() => {
          if (this.speechSynthesis && this.speechSynthesis.speaking) {
            this.speechSynthesis.cancel();
          }
        }, 10);
        
        setTimeout(() => {
          if (this.speechSynthesis && this.speechSynthesis.speaking) {
            this.speechSynthesis.cancel();
          }
        }, 100);
      }

      // ìŒì„± ì¸ì‹ ì¤‘ì§€
      if (this.currentRecognition && this._processingState === 'listening') {
        this.currentRecognition.stop();
        this.currentRecognition = undefined;
      }

      this.setProcessingState('idle');
      
      this.emitSpeechEvent({
        type: 'end',
        timestamp: Date.now(),
        data: { state: 'idle' }
      });
      
      console.log('ğŸ”‡ ëª¨ë“  ìŒì„± ì²˜ë¦¬ ì¤‘ë‹¨ (í”ŒëŸ¬ê·¸ì¸)');
      return Ok(undefined);
    } catch (error) {
      console.error('âŒ ìŒì„± ì¤‘ë‹¨ ì˜¤ë¥˜ (í”ŒëŸ¬ê·¸ì¸):', error);
      return Err(error as Error);
    }
  }

  /**
   * ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
   */
  isProcessing(): boolean {
    return this._processingState !== 'idle';
  }

  /**
   * ì§€ì› ì–¸ì–´ ëª©ë¡
   */
  async getSupportedLanguages(): Promise<Result<readonly string[]>> {
    return this.safeAsync(async () => {
      // Web Speech APIëŠ” ì •í™•í•œ ì–¸ì–´ ëª©ë¡ì„ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ ì–¸ì–´ë“¤ ë°˜í™˜
      return [
        'ko-KR', 'en-US', 'en-GB', 'ja-JP', 'zh-CN', 'zh-TW',
        'es-ES', 'fr-FR', 'de-DE', 'it-IT', 'pt-PT', 'ru-RU'
      ];
    }, 'Failed to get supported languages');
  }

  /**
   * ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡
   */
  async getAvailableVoices(): Promise<Result<readonly SpeechSynthesisVoice[]>> {
    if (!this.speechSynthesis) {
      return Err(new Error('Speech synthesis not available'));
    }

    return this.safeAsync(async () => {
      return new Promise<readonly SpeechSynthesisVoice[]>((resolve) => {
        const getVoices = () => {
          const voices = this.speechSynthesis!.getVoices();
          if (voices.length > 0) {
            resolve(voices);
          } else {
            // ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ë¹„ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œë¨
            setTimeout(getVoices, 100);
          }
        };
        getVoices();
      });
    }, 'Failed to get available voices');
  }

  /**
   * Speech ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
   */
  onSpeechEvent(handler: SpeechEventHandler): void {
    this.speechEventHandlers.add(handler);
  }

  /**
   * Speech ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì œê±°
   */
  offSpeechEvent(handler: SpeechEventHandler): void {
    this.speechEventHandlers.delete(handler);
  }

  /**
   * Speech ì´ë²¤íŠ¸ ë°œìƒ
   */
  private emitSpeechEvent(event: SpeechPluginEvent): void {
    this.speechEventHandlers.forEach(handler => {
      try {
        handler(event);
      } catch (error) {
        console.error('Speech event handler error:', error);
      }
    });
  }
}